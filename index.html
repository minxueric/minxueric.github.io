<!DOCTYPE HTML>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-86220446-2', 'auto');
  ga('send', 'pageview');

</script>

<title>Xu Min</title>
<meta name="description" content="Just another Open Designs template." />
<meta name="robots" content="noodp,noydir" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" id="child-theme-css" href="css/style.css" type="text/css" media="all" />
<link rel="stylesheet" id="responsive-main-css-css" href="css/responsive-main.min.css" type="text/css" media="all" />
<link rel="stylesheet" id="responsive-css-css" href="css/responsive.css" type="text/css" media="all" />
<link rel="stylesheet" id="tb_styles-css" href="css/tb-styles.min.css" type="text/css" media="all" />
    <link href='http://fonts.googleapis.com/css?family=Cabin+Sketch:400,700' rel='stylesheet'   type='text/css'/>

<script type="text/javascript" src="js/jquery.js"></script>

<script type="text/javascript">
  jQuery(window).scroll(function (event) {
	  	
		var top = jQuery('#popular-upcoming').offset().top - jQuery(document).scrollTop();
		var top2 = jQuery('#contacts').offset() - jQuery(document).scrollTop();
		// what the y position of the scroll is
		var y = jQuery(this).scrollTop();
		// whether that's below the form
		if (y >= top)  {
		// if so, add the active class to popular-upcoming and remove from content
		jQuery('.page-nav-popular-posts').addClass('active');
		jQuery('.page-nav-top-posts').removeClass('active');
		} else {
		// otherwise remove it
		jQuery('.page-nav-popular-posts').removeClass('active');
		jQuery('.page-nav-top-posts').addClass('active');
	   }
  });
  
  jQuery(document).ready(function (){
  jQuery('#popular-scroll').click(function (){
            //jQuery(this).animate(function(){
                jQuery('html, body').animate({
                    scrollTop: jQuery('#popular-upcoming').offset().top
                     }, 1000);
            //});
        });

		jQuery('#contact-scroll').click(function (){
            //jQuery(this).animate(function(){
                jQuery('html, body').animate({
                    scrollTop: jQuery('#contact').offset().top
                     }, 1000);
            //});
        });
		
		jQuery('#feature-scroll').click(function (){
            //jQuery(this).animate(function(){
                jQuery('html, body').animate({
                    scrollTop: jQuery('#inner').offset().top
                     }, 1000);
            //});
        });
		  });
	  </script>
</head>

<body class="home blog header-full-width full-width-content">
  <div id="header">
  <div class="site-header">
    <h1 class="site-header-logo-container">
    <a href="/"><span class="image-replace">Name</span>
    <img src="images/mylogo.png" width="65" height="35" id="bigg-logo" alt="" /></a>
    </h1>
      
            <ul id="page-nav" class="horizontal-list">
<li class="page-nav-top-posts active"><a href="javascript:void(0)" id="feature-scroll" class="page-anchor-link">Home</a></li>
<li class="page-nav-popular-posts"><a href="javascript:void(0)" id="popular-scroll" class="page-anchor-link">Publications</a></li>
<li class="page-nav-contact-posts"><a href="javascript:void(0)" id="contact-scroll" class="page-anchor-link">Contact</a></li>

</ul>

<div id="site-nav" class="horizontal-list"><div class="menu-main-menu-container"><ul id="menu-main-menu" class="menu">
</ul></div></div><!-- #site-nav -->


<div id="site-header-bigg-social">
<ul class="horizontal-list">
<li><a href="https://twitter.com/_beenkim" target="_blank" class="bigg-social-twitter bigg-social-icon image-replace">Twitter</a></li>
<li><a href="http://scholar.google.com/citations?hl=en&user=aGXkhcwAAAAJ" target="_blank" class="bigg-social-gplus bigg-social-icon image-replace">Google+</a></li>

</ul>
      
    </div>  
    </div>
  </div>
  <div id="wrap">
<div id="inner">
<div class="wrap">
<div id="content-sidebar-wrap">
				
				<div id="content" class="hfeed">
				<div class="post-5 post type-post status-publish format-standard hentry category-featured category-parent-category-i entry feature feature">

		<img width="200" height="200" src="images/Xu_Min.jpg" class="alignleft post-image" alt="1" />
    <h3 class=cabin-sketch>
        <br/>
    <img src="images/mylogo.png" width="200" id="bigg-logo" alt="" />
    <br/>
    <p class=cabin-sketch>
	    Research Scientist at IBM Research China </p></h3>
      <br/>
      <br/>

    </h4>
		
				<div class="entry-content">
      <br/>
      <br/>
      <br/>
      <br/>
      <br/>
 	<p>
I am interested in designing high-performance machine learning methods that make sense <b>to humans</b>.
      <a href="https://www.quantamagazine.org/been-kim-is-building-a-translator-for-artificial-intelligence-20190110/"> Quanta magazine </a> described well why I am doing what I am doing. Thank you John Pavlus for writing this piece!
<!--Here are two reasons why <b>interpretable machine learning </b> matters. First, in order to enable ML to make real-world impact on important problems with serious consequences, such as medical diagnosis, policy making and disaster response, we need a system that can make sense to and be trusted by human experts. Only then will ML be trusted and widely used for these applications to make a difference in the world. The second reason is to prevent unfairness and social inequality. If ML, a very powerful tool, is not interpretable and can only be understood by a small number of highly specialized people or those who can afford them, it will deepen social inequality. By making ML models interpretable we can ensure that anyone can leverage these powerful tools.-->
<a href="https://www.facebook.com/WiMLWorkshop/photos/a.2187465001269129/1431021626913474/?type=3">Here</a> is another short writeup about why I care.
     
      <br/>
      <br/>
My focus is <b> building interpretability method for already-trained models </b>or <b>building inherently interpretable models </b>. In particular, I believe
the language of explanations should include <b>higher-level, human-friendly concepts</b> so that it can make sense to <b> everyone </b>.
      <br/>
      <br/>
 <!--     My work was also featured in an episode in <a href="https://www.thetalkingmachines.com/episodes/explainability-and-inexplicable"> Talking Machine </a> (which I have not had courage to listen myself talking). 
      Many thanks for Katherine Gorman!
      I built interpretable latent variable models (featured at <a href="http://www.thetalkingmachines.com/blog/2016/1/15/real-human-actions-and-women-in-machine-learning"> Talking Machines</a>, and 
      <a href="http://newsoffice.mit.edu/2014/pattern-recognition-systems-convey-learning-1205" >MIT news</a>)
      and creating structured Bayesian models of human decisions.
      I have applied these ideas to data from various domains: computer programming education, autism spectrum discorder data, recipes, disease data, 15 years of crime data from the city of Cambridge, human dialogue data from the AMI meeting corpus, and text-based chat data during disaster response. 
      I graduated with a PhD from <a href="http://csail.mit.edu/"> CSAIL</a>, <a href="http://mit.edu/"> MIT</a>.
(worked with 
      Prof. <a href="http://people.csail.mit.edu/julie_a_shah/Welcome.html" > Julie Shah </a> 
      and Prof. <a href="http://web.mit.edu/rudin/www/Mypage.html"> Cynthia Rudin</a>).-->
      <br/>
	  <br/>

    I gave a couple of tutorials on interpretability:
      <br/>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Deep Learning Summer school at University of Toronto, Vector institute in 2018 (<a href="slides/DLSS2018Vector_Been.pdf">slides</a>, <a href="https://vectorinstitute.ai/faq-items/2018-deep-learning-summer-school">video</a>)
      <br/>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CVPR 2018 (<a href="https://interpretablevision.github.io/index_cvpr2018.html">slides and videos</a>)
      <br/>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://2017.icml.cc/Conferences/2017/Tutorials">Tutorial on Interpretable machine learning at ICML 2017</a> (<a href="papers/BeenK_FinaleDV_ICML2017_tutorial.pdf">slides</a>,  <a href="https://icml.cc/Conferences/2017/Schedule?showEvent=900" >video</a>).
      <br/>
 	<p>

Other stuff I help with:
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Workshop Chair at ICLR 2018
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Senior program committee at AISTATS 2019
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Area chair and program chair at <a href="https://nips.cc/Conferences/2017/Committees">NIPS 2017, NeurIPS 2018 and 2019</a>, ICML 2019
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Steering committee and area chair at <a href="https://fatconference.org/"> FAT* conference</a> 
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Program committee at ICML 2017/2018, AAAI 2017, IJCAI 2016 (and many other conference before that...)
      <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Executive board member of <a href="http://wimlworkshop.org/board/">  Women in Machine Learning</a>.
<!--My work on interpretable machine learing was feature at <a href="http://www.thetalkingmachines.com/blog/2016/1/15/real-human-actions-and-women-in-machine-learning"> Talk machines by Hanna Wallach</a> on January 14, 2016.-->
<br>      
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Co-organizer <a href="https://sites.google.com/corp/view/whi2018">3rd ICML 2018 Worshop on Human Interpretability in Machine Learning (WHI)</a>, <a href="https://sites.google.com/site/2016whi/">1st ICML 2016 Worshop on Human Interpretability in Machine Learning (WHI)</a>,
 <a href="https://sites.google.com/view/whi2017/home">2nd ICML 2017 Worshop on Human Interpretability in Machine Learning (WHI).</a>
and <a href="https://sites.google.com/site/nips2016interpretml">NIPS 2016 Worshop on Interpretable Machine Learning for Complex Systems</a>.       <br/>
      </p>
      </p>
     <br>
      </p>
      <br/>
      <a class="bigg-read-more" href="http://scholar.google.com/citations?hl=en&user=aGXkhcwAAAAJ">Google Scholar</a>
      <br/>

    </div><!-- end .entry-content -->
	</div><!-- end .postclass -->

<br>
<br>


      
     <hr color='#D6D6D6'>
      <h2> Publications </h2>

		<div id="popular-upcoming" >
      </div>
 

  <!------------ start one posting ------------>
		<a href="https://arxiv.org/abs/1711.11279" title=""><img width="350" height="213" src="images/TCAV_doctor.png" class="alignleft post-image" alt="2" /></a>		
    <h2 class="entry-title">
      <a href="https://arxiv.org/abs/1711.11279" >
Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)
      </a>
    </h2> 
<b>
TL;DR: We can learn human-concepts in any layer of already-trained neural networks. Then we can do hypothesis testing with them to get quantitative explanations.
</b>
<div class="entry-content">
<p>
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, Rory Sayres 
    <br />
    <i></i>ICML 2018 <br />
    [<a href="https://arxiv.org/abs/1711.11279">pdf</a>]
    [<a href="https://github.com/tensorflow/tcav">code</a>]
    [<a href="bibs/TCAVKim17.bib">bibtex</a>]
    [<a href="slides/TCAV_ICML_pdf.pdf">slides</a>]
     <br/>
     <br/><img width="350" height="213" src="images/sundar.png" class="alignleft post-image" alt="2" />
     <a href="https://en.wikipedia.org/wiki/Sundar_Pichai"> Sundar Pichai </a> (CEO of Google)'s presenting TCAV as a tool to build AI for everyone at his keynote speech at Google I/O 2019
    [<a href="https://youtu.be/lyRPyRKHO8M?t=2156">video</a>]
     <br/>
    <br/>
    <br/>
    </div><!-- end .entry-content -->
      <!------------ end one posting ------------>

 



      <!------------ start one posting ------------>
		<a href="papers/BKim10ICRA.pdf" title="A Post With Everything In It"><img width="350" height="168" src="images/icra10_thumb.png" class="alignleft post-image" alt="7" /></a>		
    <h2 class="entry-title"><a href="papers/BKim10ICRA.pdf" title="A Post With Everything In It" rel="bookmark"> 
		Multiple Relative Pose Graphs for Robust Cooperative Mapping</a></h2>

				<div class="entry-content">
	<p>
Been Kim, Michael Kaess, Luke Fletcher, John Leonard, Abraham Bachrach, Nicholas Roy, and Seth Teller <br />
International Conference on Robotics and Automation 2010 <br />
[<a href="papers/BKim10ICRA.pdf">pdf</a>]
[<a href="bibs/BKimICRA10">bibtex</a>]
[<a href="http://youtu.be/_d6p9VhDsF8">video</a>]

		</p>
    </div><!-- end .entry-content -->
	
     <!------------ end one posting ------------>


     
      		
     <hr color='#D6D6D6'>
      <h2> Thesis</h2>

		<a href="papers/BKimPhDThesis.pdf" title="Hello world!"><img width="350" height="213" src="images/thesis_thumb.png" class="alignleft post-image" alt="2" /></a>		
    <h2 class="entry-title">
      <a href="papers/BKimPhDThesis.pdf" >
      Interactive and Interpretable Machine Learning Models for Human Machine Collaboration
      </a>
    </h2> 
		<div class="entry-content">
			<p>
    Been Kim<br />
    <i></i>PhD Thesis 2015<br />
    [<a href="papers/BKimPhDThesis.pdf">pdf</a>]
    [<a href="bibs/BKimPhDThesisBib">bibtex</a>]
    <!--[<a href="papers/BKimPhDThesis_slides">slides</a>]-->
</p>
    </div><!-- end .entry-content -->
    <br >
    <br >
    <br >
    <br >
		


	
     



     <hr color='#D6D6D6'>
		<div id="contact" >
      <h2> Contact </h2>
      <br/>
      <br/>
      <br/>
    <img src="images/email.jpg" width="200" id="bigg-logo" alt="" /></a>
	</div><!-- end .wrap -->
</div><!-- end #inner --> 

  <!--
<div id="bigg-footer">

<div class="wrap">
        <div class="twocol">
            <div id="text-2" class="widget widget_text"><div class="widget-wrap"><h4 class="widgettitle">Company</h4>			
			<div class="textwidget"><ul class="plain-list">
<li><a href="#">About</a></li>
<li><a href="#">Jobs</a></li>
<li><a href="#">Contact</a></li>
<li><a href="#">Terms</a></li>
<li><a href="#">Privacy</a></li>
</ul>
</div>
		</div></div>
        </div>
        <div class="twocol">
            <div id="text-3" class="widget widget_text"><div class="widget-wrap"><h4 class="widgettitle">Community</h4>			<div class="textwidget"><ul class="plain-list">
<li><a href="#">Blog</a></li>
<li><a href="#">Twitter</a></li>
<li><a href="#">Facebook</a></li>
<li><a href="#">Help</a></li>
</ul>
</div>
		</div></div>
        </div>
        <div class="fourcol">
            <div id="text-4" class="widget widget_text"><div class="widget-wrap"><h4 class="widgettitle">Subscribe to the newsletter</h4>			<div class="textwidget"><p>Top stories from Bigg delivered to your inbox</p>

<div>
<input type="text" placeholder="Enter your email address" name="email" class="form-field" id="newsletter-email-input"> <input type="button" value="Submit" class="button" id="newsletter-email-submit-btn">
</div>

<p class="legalese">
Opt-out anytime with one click and we'll never share your information.
</p></div>
		</div></div>
        </div>
        <div class="fourcol last">
            <div id="text-5" class="widget widget_text"><div class="widget-wrap"><h4 class="widgettitle">Free download</h4>			<div class="textwidget"><p>Bigg is a completely free website template that you can download and start tinkering with right away.</p>

<a class="button" href="http://www.opendesigns.org/design/bigg/">Download now!</a></div>
		</div></div>
        </div>
		            </div>
</div>
 
</div><!-- end #wrap -->

</div>
</body>
</html>
    <div class="footer-copyright clear">
Copy Right © Xu Min <span id="footer-copyright-year"> 2019</span>  </a>
</div>

